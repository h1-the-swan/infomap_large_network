For very large networks (on the scale of ~1 billion edges), Infomap clustering does not complete in a reasonable time. Instead, run RelaxMap (parallel implementation of Infomap) to get a two-level partition, then extract subgraphs and run hierarchical infomap on those.

2018-12-23
tests with `jstor.net`
`nohup ~/code/RelaxMap/ompRelaxmap 999 ~/code/infomap_large_network/data/jstor.net 18 1 1e-4 0.0 10 ~/code/infomap_large_network/data/ prior >& relaxmap_jstor_run_20181223.log &`


2019-01-02
MySQL:
>> LOAD DATA LOCAL INFILE 'data/wos_hierInfomap_tree_coltrim_tsv_20190102/part-00000-5aa860f2-6f22-4d06-93a7-ae6623973d0a-c000.csv' INTO TABLE `wos`.`tree_rank_multilevel` IGNORE 1 LINES;
Query OK, 146151683 rows affected (1 hour 13 min 25.20 sec)
Records: 146151683  Deleted: 0  Skipped: 0  Warnings: 0


2019-01-03
After running RelaxMap to get a two-level .tree file, the hierarchical tree file can be generated by running three programs.
+ `spark_infomap_subclusters.py`
+ `finalize_tree.py`
+ `trim_final_tsv.py`

Running infomap in the `spark_infomap_subclusters.py` file was causing an error message: 'swig/python detected a memory leak of type 'std::pair< infomap::StateNetwork::NodeMap::iterator,bool > *', no destructor found.' for every node. Calling `disown()` on the object returned by `addNode()` seems to fix it.

On WoS (146151683 vertices, 1169689929 edges in network):
+ `spark_infomap_subclusters.py` took ~2 hours
+ `finalize_tree.py` took ~1.5 hours
+ `trim_final_tsv.py` took 8 minutes

